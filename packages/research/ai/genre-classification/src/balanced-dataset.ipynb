{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.12/site-packages (2.5.1+cu124)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.12/site-packages (from evaluate) (0.3.9)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.12/site-packages (from evaluate) (4.67.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers[torch])\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (2.5.1+cu124)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.2)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate) (2024.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading wandb-0.19.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m344.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m218.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m189.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: xxhash, setproctitle, sentry-sdk, safetensors, regex, propcache, multidict, fsspec, frozenlist, docker-pycreds, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, wandb, tokenizers, aiohttp, transformers, accelerate, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed accelerate-1.3.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 datasets-3.2.0 dill-0.3.8 docker-pycreds-0.4.0 evaluate-0.4.3 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.27.1 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 regex-2024.11.6 safetensors-0.5.2 sentry-sdk-2.20.0 setproctitle-1.3.4 tokenizers-0.21.0 transformers-4.48.1 wandb-0.19.4 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate transformers[torch] torchaudio wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datasets import DatasetDict, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bad',\n",
       " 'Bassy',\n",
       " 'Big Room',\n",
       " 'Bounce',\n",
       " 'Chill',\n",
       " 'Chillstep',\n",
       " 'Classic',\n",
       " 'Coding',\n",
       " 'Country',\n",
       " 'Cro',\n",
       " 'Deep House',\n",
       " 'Drum and Bass',\n",
       " 'Dubstep',\n",
       " 'EDM',\n",
       " 'Electro',\n",
       " 'Electro House',\n",
       " 'Emotional',\n",
       " 'Epic',\n",
       " 'Folk',\n",
       " 'Frenchcore',\n",
       " 'Glitch Hop',\n",
       " 'God',\n",
       " 'Groove',\n",
       " 'Hands Up',\n",
       " 'Hardcore',\n",
       " 'Hardstyle',\n",
       " 'Harp',\n",
       " 'Hip Hop & Rap',\n",
       " 'Historic',\n",
       " 'Latino',\n",
       " 'Lounge',\n",
       " 'Malle',\n",
       " 'Minimal',\n",
       " 'Motivation',\n",
       " 'Orchestra Pop',\n",
       " 'Orchestral Electro',\n",
       " 'OVERWERK',\n",
       " 'Pop',\n",
       " 'Pop mit Beat',\n",
       " 'Psy',\n",
       " 'Psytrance',\n",
       " 'RnB',\n",
       " 'Rock',\n",
       " 'Synthpop',\n",
       " 'Techno',\n",
       " 'Tekk',\n",
       " 'Trance',\n",
       " 'Weihnachten']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./dataset/genres.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    genres = json.load(f)\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 16378\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 2342\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 4675\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset = DatasetDict.load_from_disk(\"./dataset/music_lib\")\n",
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train samples: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16378/16378 [00:58<00:00, 278.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4764, 11614)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_songs_per_genre = 25\n",
    "\n",
    "counter = { genre: 0 for genre in genres }\n",
    "\n",
    "indices_to_train = []\n",
    "indices_to_test = []\n",
    "\n",
    "current_song = \"\"\n",
    "keep = True\n",
    "for idx, sample in tqdm(enumerate(preprocessed_dataset[\"train\"]), desc=\"Processing train samples\", total=len(preprocessed_dataset[\"train\"])):\n",
    "    if current_song != sample[\"paths\"]:\n",
    "        current_song = sample[\"paths\"]\n",
    "        genre = genres[sample[\"labels\"]]\n",
    "        if counter[genre] == 25:\n",
    "           keep = False\n",
    "        else:\n",
    "            keep = True\n",
    "            counter[genre] += 1\n",
    "    if keep:\n",
    "        indices_to_train.append(idx)\n",
    "    else:\n",
    "        indices_to_test.append(idx)\n",
    "    \n",
    "len(indices_to_train), len(indices_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Harp': 5,\n",
       " 'Coding': 5,\n",
       " 'Folk': 5,\n",
       " 'Synthpop': 5,\n",
       " 'Psytrance': 5,\n",
       " 'Epic': 5,\n",
       " 'Pop': 5,\n",
       " 'OVERWERK': 5,\n",
       " 'Weihnachten': 10,\n",
       " 'God': 10,\n",
       " 'Orchestra Pop': 10,\n",
       " 'Bassy': 10,\n",
       " 'Emotional': 10,\n",
       " 'Pop mit Beat': 10,\n",
       " 'Historic': 10,\n",
       " 'Dubstep': 15,\n",
       " 'Glitch Hop': 15,\n",
       " 'Orchestral Electro': 15,\n",
       " 'Chillstep': 15,\n",
       " 'Tekk': 15,\n",
       " 'RnB': 19,\n",
       " 'Minimal': 20,\n",
       " 'Chill': 20,\n",
       " 'Deep House': 20,\n",
       " 'Latino': 20,\n",
       " 'Drum and Bass': 25,\n",
       " 'EDM': 25,\n",
       " 'Cro': 30,\n",
       " 'Big Room': 30,\n",
       " 'Psy': 35,\n",
       " 'Frenchcore': 35,\n",
       " 'Classic': 39,\n",
       " 'Malle': 45,\n",
       " 'Country': 45,\n",
       " 'Groove': 49,\n",
       " 'Electro House': 55,\n",
       " 'Hip Hop & Rap': 55,\n",
       " 'Motivation': 55,\n",
       " 'Lounge': 55,\n",
       " 'Techno': 60,\n",
       " 'Bounce': 79,\n",
       " 'Hardcore': 80,\n",
       " 'Rock': 83,\n",
       " 'Electro': 85,\n",
       " 'Hardstyle': 110,\n",
       " 'Bad': 148,\n",
       " 'Trance': 150,\n",
       " 'Hands Up': 685}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ genres[k]: v for k,v in sorted(Counter(preprocessed_dataset[\"validate\"][\"labels\"]).items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 4764\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 2342\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 16289\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_dataset = DatasetDict({\n",
    "    \"train\": preprocessed_dataset[\"train\"].select(indices_to_train),\n",
    "    \"validate\": preprocessed_dataset[\"validate\"],\n",
    "    \"test\": concatenate_datasets([preprocessed_dataset[\"test\"], preprocessed_dataset[\"train\"].select(indices_to_test)])\n",
    "})\n",
    "\n",
    "balanced_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{26: 20,\n",
       " 18: 20,\n",
       " 43: 20,\n",
       " 37: 25,\n",
       " 40: 30,\n",
       " 36: 40,\n",
       " 17: 40,\n",
       " 7: 40,\n",
       " 28: 56,\n",
       " 38: 65,\n",
       " 21: 70,\n",
       " 47: 75,\n",
       " 34: 80,\n",
       " 16: 80,\n",
       " 1: 85,\n",
       " 5: 99,\n",
       " 45: 100,\n",
       " 35: 105,\n",
       " 20: 108,\n",
       " 30: 120,\n",
       " 19: 120,\n",
       " 0: 123,\n",
       " 3: 123,\n",
       " 9: 123,\n",
       " 39: 124,\n",
       " 15: 124,\n",
       " 13: 124,\n",
       " 14: 125,\n",
       " 23: 125,\n",
       " 27: 125,\n",
       " 42: 125,\n",
       " 22: 125,\n",
       " 41: 125,\n",
       " 46: 125,\n",
       " 24: 125,\n",
       " 2: 125,\n",
       " 25: 125,\n",
       " 31: 125,\n",
       " 4: 125,\n",
       " 8: 125,\n",
       " 29: 125,\n",
       " 11: 125,\n",
       " 6: 125,\n",
       " 10: 125,\n",
       " 32: 125,\n",
       " 33: 125,\n",
       " 44: 125,\n",
       " 12: 125}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{ k: v for k,v in sorted(Counter(balanced_dataset[\"train\"][\"labels\"]).items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650cb8db7a97478e92e0c8caa1427091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/4764 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e83aaf262d4bea926a8ccfaafe2209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/2342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7986990be784219bcfbfd554e35cdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/9 shards):   0%|          | 0/16289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balanced_dataset.save_to_disk(\"./dataset/music_lib_balanced\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
