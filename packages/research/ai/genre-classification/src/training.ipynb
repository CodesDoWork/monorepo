{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.12/site-packages (2.5.1+cu124)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.12/site-packages (from evaluate) (0.3.9)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.12/site-packages (from evaluate) (4.67.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.17-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers[torch])\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers[torch])\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.12/site-packages (from transformers[torch]) (2.5.1+cu124)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.12/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (5.28.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.12/site-packages (from wandb) (6.1.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /opt/conda/lib/python3.12/site-packages (from wandb) (2.10.2)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=2.6->wandb) (2.27.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->evaluate) (2024.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading wandb-0.19.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m166.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Downloading sentry_sdk-2.20.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m229.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
      "Downloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m156.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m193.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (243 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n",
      "Installing collected packages: xxhash, setproctitle, sentry-sdk, safetensors, regex, propcache, multidict, fsspec, frozenlist, docker-pycreds, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, wandb, tokenizers, aiohttp, transformers, accelerate, datasets, evaluate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed accelerate-1.3.0 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 datasets-3.2.0 dill-0.3.8 docker-pycreds-0.4.0 evaluate-0.4.3 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.27.1 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 regex-2024.11.6 safetensors-0.5.2 sentry-sdk-2.20.0 setproctitle-1.3.4 tokenizers-0.21.0 transformers-4.48.0 wandb-0.19.4 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate transformers[torch] torchaudio wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "import random\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter \n",
    "from datasets import DatasetDict\n",
    "from torch import tensor, Tensor\n",
    "from torchaudio import transforms\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import interpolate, pad\n",
    "from transformers.trainer_utils import EvalPrediction\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from transformers import ASTFeatureExtractor, ASTConfig, ASTForAudioClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=genre_classification\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=genre_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcodesdowork\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for wandb.justinkonratt.com to your netrc file: /home/jovyan/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"...\", host=\"https://wandb.justinkonratt.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bad',\n",
       " 'Bassy',\n",
       " 'Big Room',\n",
       " 'Bounce',\n",
       " 'Chill',\n",
       " 'Chillstep',\n",
       " 'Classic',\n",
       " 'Coding',\n",
       " 'Country',\n",
       " 'Cro',\n",
       " 'Deep House',\n",
       " 'Drum and Bass',\n",
       " 'Dubstep',\n",
       " 'EDM',\n",
       " 'Electro',\n",
       " 'Electro House',\n",
       " 'Emotional',\n",
       " 'Epic',\n",
       " 'Folk',\n",
       " 'Frenchcore',\n",
       " 'Glitch Hop',\n",
       " 'God',\n",
       " 'Groove',\n",
       " 'Hands Up',\n",
       " 'Hardcore',\n",
       " 'Hardstyle',\n",
       " 'Harp',\n",
       " 'Hip Hop & Rap',\n",
       " 'Historic',\n",
       " 'Latino',\n",
       " 'Lounge',\n",
       " 'Malle',\n",
       " 'Minimal',\n",
       " 'Motivation',\n",
       " 'Orchestra Pop',\n",
       " 'Orchestral Electro',\n",
       " 'OVERWERK',\n",
       " 'Pop',\n",
       " 'Pop mit Beat',\n",
       " 'Psy',\n",
       " 'Psytrance',\n",
       " 'RnB',\n",
       " 'Rock',\n",
       " 'Synthpop',\n",
       " 'Techno',\n",
       " 'Tekk',\n",
       " 'Trance',\n",
       " 'Weihnachten']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./dataset/genres.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    genres = json.load(f)\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 16378\n",
       "    })\n",
       "    validate: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 2342\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_values', 'labels', 'paths'],\n",
       "        num_rows: 4675\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset = DatasetDict.load_from_disk(\"./dataset/music_lib\")\n",
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "feature_extractor = ASTFeatureExtractor.from_pretrained(pretrained_model)\n",
    "\n",
    "model_input_name = feature_extractor.model_input_names[0]\n",
    "labels_name = \"labels\"\n",
    "paths_name = \"paths\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ASTForAudioClassification were not initialized from the model checkpoint at MIT/ast-finetuned-audioset-10-10-0.4593 and are newly initialized because the shapes did not match:\n",
      "- audio_spectrogram_transformer.embeddings.position_embeddings: found shape torch.Size([1, 1214, 768]) in the checkpoint and torch.Size([1, 590, 768]) in the model instantiated\n",
      "- classifier.dense.bias: found shape torch.Size([527]) in the checkpoint and torch.Size([48]) in the model instantiated\n",
      "- classifier.dense.weight: found shape torch.Size([527, 768]) in the checkpoint and torch.Size([48, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = ASTConfig.from_pretrained(pretrained_model)\n",
    "config.num_labels = len(genres)\n",
    "config.label2id = { genre: idx for idx, genre in enumerate(genres) }\n",
    "config.id2label = { idx: genre for idx, genre in enumerate(genres) }\n",
    "config.max_length = 498\n",
    "config.hidden_dropout_prob = 0.05\n",
    "config.attention_probs_dropout_prob = 0.05\n",
    "\n",
    "model = ASTForAudioClassification.from_pretrained(pretrained_model, config=config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aggregated_accuracy(predictions: Tensor, labels: Tensor):\n",
    "    v_score = 0\n",
    "    w_score = 0\n",
    "    a_score = 0\n",
    "    m_score = 0\n",
    "\n",
    "    songs_per_genre = [0 for _ in range(len(genres))]\n",
    "    correctly_predicted_per_genre = [0 for _ in range(len(genres))]\n",
    "\n",
    "    eval_subset = None\n",
    "    for subset in preprocessed_dataset.values():\n",
    "        if len(subset) == predictions.shape[0]:\n",
    "            eval_subset = subset\n",
    "\n",
    "    entries_per_song = list(Counter(eval_subset[paths_name]).values())\n",
    "    song_count = len(entries_per_song)\n",
    "    start_idx = 0\n",
    "    for song_entries in entries_per_song:\n",
    "        label = labels[start_idx]\n",
    "        songs_per_genre[label] += 1\n",
    "        song_logits = predictions[start_idx:start_idx + song_entries,:]\n",
    "        start_idx += song_entries\n",
    "\n",
    "        # voting\n",
    "        v_pred = song_logits.argmax(dim=1).mode().values.item()\n",
    "        if v_pred == label:\n",
    "            v_score += 1\n",
    "\n",
    "        # weighting\n",
    "        confidence = song_logits.softmax(dim=1).max(dim=1).values\n",
    "        weighted_logits = (song_logits.T * confidence).T\n",
    "        w_pred = weighted_logits.mean(dim=0).argmax().item()\n",
    "        if w_pred == label:\n",
    "            w_score += 1\n",
    "\n",
    "        # average\n",
    "        a_pred = song_logits.mean(dim=0).argmax().item()\n",
    "        if a_pred == label:\n",
    "            a_score += 1\n",
    "            correctly_predicted_per_genre[label] += 1\n",
    "\n",
    "        # max\n",
    "        m_pred = song_logits.max(dim=0).values.argmax().item()\n",
    "        if m_pred == label:\n",
    "            m_score += 1\n",
    "\n",
    "    return {\n",
    "        \"voting_score\": v_score / song_count,\n",
    "        \"weighting_score\": w_score / song_count,\n",
    "        \"mean_pooling_score\": a_score / song_count,\n",
    "        \"max_pooling_score\": m_score / song_count,\n",
    "        **{ f\"{genre}_a_accuracy\": correctly_predicted_per_genre[idx] / songs_per_genre[idx] for idx, genre in enumerate(genres) }\n",
    "    }\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "AVERAGE = \"macro\" if config.num_labels > 2 else \"binary\"\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    metrics = accuracy.compute(predictions=predictions, references=labels)\n",
    "    metrics.update(precision.compute(predictions=predictions, references=labels, average=AVERAGE))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=labels, average=AVERAGE))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=labels, average=AVERAGE))\n",
    "    metrics.update(calc_aggregated_accuracy(tensor(logits), tensor(labels)))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spectrum(specs, size=(10,6), cols=1, rows=1):\n",
    "    plt.figure(figsize=size)\n",
    "    for idx, spec in enumerate(specs):\n",
    "        plt.subplot(rows, cols, idx + 1)\n",
    "        plt.imshow(spec.T, aspect='auto', origin='lower', cmap='viridis')\n",
    "        plt.colorbar(label=\"Amplitude\")\n",
    "        plt.xlabel(\"Time Frames\")\n",
    "        plt.ylabel(\"Frequency Bins\")\n",
    "        plt.tight_layout()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecAugmentPipeline:\n",
    "    def __init__(\n",
    "            self,\n",
    "            p=0.5,\n",
    "            effects_p=0.5,\n",
    "            time_mask_param=30,\n",
    "            freq_mask_param=20,\n",
    "            noise_level=0.05,\n",
    "            stretch_range=(0.95, 1.05),\n",
    "            shift_range=3,\n",
    "            amplitude_range=(0.8, 1.2)\n",
    "    ):\n",
    "        self.p = p\n",
    "        self.effects_p = effects_p\n",
    "        self.time_mask = transforms.TimeMasking(time_mask_param)\n",
    "        self.freq_mask = transforms.FrequencyMasking(freq_mask_param)\n",
    "        self.noise_level = noise_level\n",
    "        self.stretch_range = stretch_range\n",
    "        self.shift_range = shift_range\n",
    "        self.amplitude_range = amplitude_range\n",
    "\n",
    "    def add_noise(self, spec):\n",
    "        return spec + torch.randn_like(spec) * self.noise_level\n",
    "    \n",
    "    def time_stretch(self, spec):\n",
    "        spec = spec.unsqueeze(0)\n",
    "        factor = random.uniform(*self.stretch_range)\n",
    "        new_steps = int(spec.size(-1) * factor)\n",
    "        new_spec = interpolate(spec, (spec.size(-2), new_steps), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        return new_spec.resize_(spec.size(-3), spec.size(-2), spec.size(-1)) if factor >= 1 else pad(new_spec, (0, spec.size(-1) - new_steps))\n",
    "\n",
    "    def frequency_shift(self, spec):\n",
    "        shift = random.randint(-self.shift_range, self.shift_range)\n",
    "        return torch.roll(spec, shifts=shift, dims=-2)\n",
    "\n",
    "    def amplitude_scaling(self, spec):\n",
    "        return spec * random.uniform(*self.amplitude_range)\n",
    "\n",
    "    def __call__(self, spec):\n",
    "        if random.random() >= self.p:\n",
    "            return spec\n",
    "        \n",
    "        spec = spec.transpose(-1, -2)\n",
    "        if random.random() < self.effects_p:\n",
    "            spec = self.time_mask(spec)\n",
    "        \n",
    "        if random.random() < self.effects_p:\n",
    "            spec = self.freq_mask(spec)\n",
    "\n",
    "        if random.random() < self.effects_p:\n",
    "            spec = self.add_noise(spec)\n",
    "\n",
    "        if random.random() < self.effects_p:\n",
    "            spec = self.time_stretch(spec)\n",
    "\n",
    "        if random.random() < self.effects_p:\n",
    "            spec = self.frequency_shift(spec)\n",
    "\n",
    "        if random.random() < self.effects_p:\n",
    "            spec = self.amplitude_scaling(spec)\n",
    "\n",
    "        return spec.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pipe = SpecAugmentPipeline(p=0.5)\n",
    "def augmentation(sample):\n",
    "    if model_input_name in sample:\n",
    "        sample[model_input_name] = aug_pipe(tensor(sample[model_input_name]))\n",
    "    return sample\n",
    "\n",
    "preprocessed_dataset[\"train\"].set_transform(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3256,  4.0142,  1.6644,  0.6226,  2.5275,  3.4465,  1.2057,  8.5302,\n",
       "         1.0832,  1.8149,  2.6247,  2.0679,  2.7297,  1.9062,  0.5557,  0.8817,\n",
       "         4.2651,  8.5302, 17.0604,  1.5509,  3.1593,  4.8744,  0.9612,  0.0710,\n",
       "         0.6261,  0.4414, 17.0604,  0.8794,  6.0930,  2.3532,  0.9833,  1.0832,\n",
       "         2.5275,  0.8530,  4.2651,  3.2496,  8.5302, 13.6483,  5.2494,  1.4582,\n",
       "        11.3736,  2.3532,  0.5603, 17.0604,  0.7898,  3.4121,  0.3243,  4.5494],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = preprocessed_dataset[\"train\"][labels_name]\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float, device=\"cuda\")\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_loss_func(outputs, labels, num_items_in_batch):\n",
    "    logits = outputs.get(\"logits\")\n",
    "    loss_fct = CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
    "    return loss_fct(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "devices = 2\n",
    "warmup_epochs = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./runs/ast_classifier\",\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"better_stretch\",\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=round(len(preprocessed_dataset[\"train\"]) / batch_size * warmup_epochs),\n",
    "    push_to_hub=False,\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=batch_size // devices,\n",
    "    per_device_eval_batch_size=batch_size // devices,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mean_pooling_score\",\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    fp16=True,\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=preprocessed_dataset[\"train\"],\n",
    "    eval_dataset=preprocessed_dataset[\"validate\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    compute_loss_func=weighted_loss_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcodesdowork\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jkonratt/genre_classification/wandb/run-20250120_142733-zezuv4zi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.justinkonratt.com/codesdowork/genre_classification/runs/zezuv4zi' target=\"_blank\">better_stretch</a></strong> to <a href='https://wandb.justinkonratt.com/codesdowork/genre_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.justinkonratt.com/codesdowork/genre_classification' target=\"_blank\">https://wandb.justinkonratt.com/codesdowork/genre_classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.justinkonratt.com/codesdowork/genre_classification/runs/zezuv4zi' target=\"_blank\">https://wandb.justinkonratt.com/codesdowork/genre_classification/runs/zezuv4zi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='520' max='1920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 520/1920 32:16 < 1:27:13, 0.27 it/s, Epoch 4.05/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Voting Score</th>\n",
       "      <th>Weighting Score</th>\n",
       "      <th>Mean Pooling Score</th>\n",
       "      <th>Max Pooling Score</th>\n",
       "      <th>Bad A Accuracy</th>\n",
       "      <th>Bassy A Accuracy</th>\n",
       "      <th>Big room A Accuracy</th>\n",
       "      <th>Bounce A Accuracy</th>\n",
       "      <th>Chill A Accuracy</th>\n",
       "      <th>Chillstep A Accuracy</th>\n",
       "      <th>Classic A Accuracy</th>\n",
       "      <th>Coding A Accuracy</th>\n",
       "      <th>Country A Accuracy</th>\n",
       "      <th>Cro A Accuracy</th>\n",
       "      <th>Deep house A Accuracy</th>\n",
       "      <th>Drum and bass A Accuracy</th>\n",
       "      <th>Dubstep A Accuracy</th>\n",
       "      <th>Edm A Accuracy</th>\n",
       "      <th>Electro A Accuracy</th>\n",
       "      <th>Electro house A Accuracy</th>\n",
       "      <th>Emotional A Accuracy</th>\n",
       "      <th>Epic A Accuracy</th>\n",
       "      <th>Folk A Accuracy</th>\n",
       "      <th>Frenchcore A Accuracy</th>\n",
       "      <th>Glitch hop A Accuracy</th>\n",
       "      <th>God A Accuracy</th>\n",
       "      <th>Groove A Accuracy</th>\n",
       "      <th>Hands up A Accuracy</th>\n",
       "      <th>Hardcore A Accuracy</th>\n",
       "      <th>Hardstyle A Accuracy</th>\n",
       "      <th>Harp A Accuracy</th>\n",
       "      <th>Hip hop & rap A Accuracy</th>\n",
       "      <th>Historic A Accuracy</th>\n",
       "      <th>Latino A Accuracy</th>\n",
       "      <th>Lounge A Accuracy</th>\n",
       "      <th>Malle A Accuracy</th>\n",
       "      <th>Minimal A Accuracy</th>\n",
       "      <th>Motivation A Accuracy</th>\n",
       "      <th>Orchestra pop A Accuracy</th>\n",
       "      <th>Orchestral electro A Accuracy</th>\n",
       "      <th>Overwerk A Accuracy</th>\n",
       "      <th>Pop A Accuracy</th>\n",
       "      <th>Pop mit beat A Accuracy</th>\n",
       "      <th>Psy A Accuracy</th>\n",
       "      <th>Psytrance A Accuracy</th>\n",
       "      <th>Rnb A Accuracy</th>\n",
       "      <th>Rock A Accuracy</th>\n",
       "      <th>Synthpop A Accuracy</th>\n",
       "      <th>Techno A Accuracy</th>\n",
       "      <th>Tekk A Accuracy</th>\n",
       "      <th>Trance A Accuracy</th>\n",
       "      <th>Weihnachten A Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.047500</td>\n",
       "      <td>3.380600</td>\n",
       "      <td>0.103757</td>\n",
       "      <td>0.079766</td>\n",
       "      <td>0.149740</td>\n",
       "      <td>0.076865</td>\n",
       "      <td>0.129787</td>\n",
       "      <td>0.129787</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.104255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.832400</td>\n",
       "      <td>2.854285</td>\n",
       "      <td>0.270282</td>\n",
       "      <td>0.278681</td>\n",
       "      <td>0.252046</td>\n",
       "      <td>0.173308</td>\n",
       "      <td>0.376596</td>\n",
       "      <td>0.365957</td>\n",
       "      <td>0.353191</td>\n",
       "      <td>0.351064</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.540146</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.875400</td>\n",
       "      <td>2.703272</td>\n",
       "      <td>0.297182</td>\n",
       "      <td>0.318177</td>\n",
       "      <td>0.322385</td>\n",
       "      <td>0.254543</td>\n",
       "      <td>0.421277</td>\n",
       "      <td>0.421277</td>\n",
       "      <td>0.408511</td>\n",
       "      <td>0.376596</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.335766</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.396500</td>\n",
       "      <td>2.552171</td>\n",
       "      <td>0.321520</td>\n",
       "      <td>0.319745</td>\n",
       "      <td>0.348444</td>\n",
       "      <td>0.276540</td>\n",
       "      <td>0.412766</td>\n",
       "      <td>0.506383</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.434043</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.452555</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._load_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 2.3468895 , -1.9537987 ,  4.9273396 , ...,  0.22495458,\n",
       "         2.7202008 , -0.7991523 ],\n",
       "       [-1.4988972 ,  0.8217171 , -0.79373574, ..., -0.9814781 ,\n",
       "        -1.1862347 , -2.207212  ],\n",
       "       [ 4.4040856 , -2.074986  ,  4.2714896 , ..., -3.085356  ,\n",
       "        -0.21997654, -1.6877873 ],\n",
       "       ...,\n",
       "       [ 6.7366014 , -1.6003168 , -0.6002155 , ..., -3.960124  ,\n",
       "        -0.43739069, -1.7418805 ],\n",
       "       [ 9.027047  , -1.838432  ,  1.3532044 , ..., -3.1699862 ,\n",
       "        -1.8196579 , -0.30163497],\n",
       "       [ 5.187873  ,  1.8964833 , -2.5847745 , ..., -1.297473  ,\n",
       "         0.1496332 ,  0.34114793]], dtype=float32), label_ids=array([35, 35, 35, ...,  0,  0,  0]), metrics={'test_loss': 2.74991774559021, 'test_accuracy': 0.533903743315508, 'test_precision': 0.39847213890473193, 'test_recall': 0.3760192702529492, 'test_f1': 0.3755052133777681, 'test_voting_score': 0.6971307120085016, 'test_weighting_score': 0.7449521785334751, 'test_mean_pooling_score': 0.7332624867162593, 'test_max_pooling_score': 0.7098831030818279, 'test_Bad_a_accuracy': 0.9180327868852459, 'test_Bassy_a_accuracy': 0.6, 'test_Big Room_a_accuracy': 0.2727272727272727, 'test_Bounce_a_accuracy': 0.7096774193548387, 'test_Chill_a_accuracy': 0.25, 'test_Chillstep_a_accuracy': 0.3333333333333333, 'test_Classic_a_accuracy': 0.8823529411764706, 'test_Coding_a_accuracy': 0.5, 'test_Country_a_accuracy': 0.5555555555555556, 'test_Cro_a_accuracy': 0.7272727272727273, 'test_Deep House_a_accuracy': 0.0, 'test_Drum and Bass_a_accuracy': 0.4444444444444444, 'test_Dubstep_a_accuracy': 0.2857142857142857, 'test_EDM_a_accuracy': 0.2727272727272727, 'test_Electro_a_accuracy': 0.6111111111111112, 'test_Electro House_a_accuracy': 0.2608695652173913, 'test_Emotional_a_accuracy': 0.8, 'test_Epic_a_accuracy': 0.6666666666666666, 'test_Folk_a_accuracy': 1.0, 'test_Frenchcore_a_accuracy': 0.38461538461538464, 'test_Glitch Hop_a_accuracy': 0.16666666666666666, 'test_God_a_accuracy': 0.0, 'test_Groove_a_accuracy': 0.85, 'test_Hands Up_a_accuracy': 0.9309090909090909, 'test_Hardcore_a_accuracy': 0.6774193548387096, 'test_Hardstyle_a_accuracy': 0.8, 'test_Harp_a_accuracy': 0.0, 'test_Hip Hop & Rap_a_accuracy': 0.5217391304347826, 'test_Historic_a_accuracy': 0.6666666666666666, 'test_Latino_a_accuracy': 0.75, 'test_Lounge_a_accuracy': 0.8571428571428571, 'test_Malle_a_accuracy': 0.9444444444444444, 'test_Minimal_a_accuracy': 1.0, 'test_Motivation_a_accuracy': 0.8260869565217391, 'test_Orchestra Pop_a_accuracy': 0.6, 'test_Orchestral Electro_a_accuracy': 0.3333333333333333, 'test_OVERWERK_a_accuracy': 0.5, 'test_Pop_a_accuracy': 0.0, 'test_Pop mit Beat_a_accuracy': 0.0, 'test_Psy_a_accuracy': 0.46153846153846156, 'test_Psytrance_a_accuracy': 0.0, 'test_RnB_a_accuracy': 0.2222222222222222, 'test_Rock_a_accuracy': 0.8285714285714286, 'test_Synthpop_a_accuracy': 0.0, 'test_Techno_a_accuracy': 0.52, 'test_Tekk_a_accuracy': 0.6, 'test_Trance_a_accuracy': 0.8, 'test_Weihnachten_a_accuracy': 0.0, 'test_runtime': 85.3719, 'test_samples_per_second': 54.76, 'test_steps_per_second': 0.433})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    results = trainer.predict(preprocessed_dataset[\"test\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create confusion matrix\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mtrue_labels\u001b[49m, predicted_labels)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Normalize the confusion matrix (optional)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m cm_normalized_row \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m cm\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Normalize the confusion matrix (optional)\n",
    "cm_normalized_row = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_normalized_row, xticklabels=genres, yticklabels=genres)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/Bad_a_accuracy</td><td>▁▁▅▆▇███</td></tr><tr><td>eval/Bassy_a_accuracy</td><td>█▁██████</td></tr><tr><td>eval/Big Room_a_accuracy</td><td>▁▅▄▅▅█▅█</td></tr><tr><td>eval/Bounce_a_accuracy</td><td>▁▂▁▇▆▇█▂</td></tr><tr><td>eval/Chill_a_accuracy</td><td>▁▁██████</td></tr><tr><td>eval/Chillstep_a_accuracy</td><td>▃▁██▃▆▁▃</td></tr><tr><td>eval/Classic_a_accuracy</td><td>▁▅▁▁▁▁█▁</td></tr><tr><td>eval/Coding_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Country_a_accuracy</td><td>▂▁▆▄▆█▆▆</td></tr><tr><td>eval/Cro_a_accuracy</td><td>▁▁▇█▆██▇</td></tr><tr><td>eval/Deep House_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Drum and Bass_a_accuracy</td><td>▁▆▁▆▆▆▆█</td></tr><tr><td>eval/Dubstep_a_accuracy</td><td>▁▁█▁▅▅▁▁</td></tr><tr><td>eval/EDM_a_accuracy</td><td>█▁▅▅█▅█▅</td></tr><tr><td>eval/Electro House_a_accuracy</td><td>▁▅▄▄▅▄▃█</td></tr><tr><td>eval/Electro_a_accuracy</td><td>▁▄▂▆▅▇▇█</td></tr><tr><td>eval/Emotional_a_accuracy</td><td>▁███████</td></tr><tr><td>eval/Epic_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Folk_a_accuracy</td><td>█▁██▁█▁▁</td></tr><tr><td>eval/Frenchcore_a_accuracy</td><td>▁▁█▄▂▂▅▇</td></tr><tr><td>eval/Glitch Hop_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/God_a_accuracy</td><td>▁▁█▁██▁▁</td></tr><tr><td>eval/Groove_a_accuracy</td><td>▃▁▇█▇▇▆▅</td></tr><tr><td>eval/Hands Up_a_accuracy</td><td>▁▇▄█▃█▇█</td></tr><tr><td>eval/Hardcore_a_accuracy</td><td>▁▃▇▆█▇█▇</td></tr><tr><td>eval/Hardstyle_a_accuracy</td><td>▁▄▄▅▆▇▆█</td></tr><tr><td>eval/Harp_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Hip Hop & Rap_a_accuracy</td><td>▁▆▆▆▅▄▇█</td></tr><tr><td>eval/Historic_a_accuracy</td><td>▁██▅████</td></tr><tr><td>eval/Latino_a_accuracy</td><td>▁▁▁████▆</td></tr><tr><td>eval/Lounge_a_accuracy</td><td>▆▁▆▆▆███</td></tr><tr><td>eval/Malle_a_accuracy</td><td>▁▁▃▂▇▇▇█</td></tr><tr><td>eval/Minimal_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Motivation_a_accuracy</td><td>▁▇▇▆▅▆█▃</td></tr><tr><td>eval/OVERWERK_a_accuracy</td><td>▁███████</td></tr><tr><td>eval/Orchestra Pop_a_accuracy</td><td>▅▁▅▅▅██▅</td></tr><tr><td>eval/Orchestral Electro_a_accuracy</td><td>▁▁▅██▅██</td></tr><tr><td>eval/Pop mit Beat_a_accuracy</td><td>▁▁▁▅█▁█▁</td></tr><tr><td>eval/Pop_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Psy_a_accuracy</td><td>▁▂█▆█▇▃▁</td></tr><tr><td>eval/Psytrance_a_accuracy</td><td>▁████▁█▁</td></tr><tr><td>eval/RnB_a_accuracy</td><td>▁▁▅▅▅▅█▅</td></tr><tr><td>eval/Rock_a_accuracy</td><td>▁▁▅▃██▆▇</td></tr><tr><td>eval/Synthpop_a_accuracy</td><td>▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/Techno_a_accuracy</td><td>█▁▃▁▁▃▅▆</td></tr><tr><td>eval/Tekk_a_accuracy</td><td>▁▆█▆▆▃▃▆</td></tr><tr><td>eval/Trance_a_accuracy</td><td>▇██▅▁▆█▆</td></tr><tr><td>eval/Weihnachten_a_accuracy</td><td>▁▁█▁▁▁▁▁</td></tr><tr><td>eval/accuracy</td><td>▁▄▅▆▅███</td></tr><tr><td>eval/f1</td><td>▁▃▆▆▆▇█▇</td></tr><tr><td>eval/loss</td><td>█▄▂▂▁▁▁▂</td></tr><tr><td>eval/max_pooling_score</td><td>▁▄▅▇▆███</td></tr><tr><td>eval/mean_pooling_score</td><td>▁▄▅▇▆███</td></tr><tr><td>eval/precision</td><td>▁▄▆▆▆▇██</td></tr><tr><td>eval/recall</td><td>▁▄▇▆▇██▇</td></tr><tr><td>eval/runtime</td><td>▁▂▂▁▄█▂▂</td></tr><tr><td>eval/samples_per_second</td><td>█▇▇█▄▁▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▆█▅▁▇▆</td></tr><tr><td>eval/voting_score</td><td>▁▄▅▆▅███</td></tr><tr><td>eval/weighting_score</td><td>▁▄▅▇▆███</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/grad_norm</td><td>▇▇▇▅█▅▇▄▆▇▄█▆▇▆▄▇▄█▇▄▅▄▄▆▅▂▄▃▅▁▂▅▂▂▁▂▁▃▂</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▂▃▃▄▅▅███▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄</td></tr><tr><td>train/loss</td><td>█▇▇▇▇▆▅▅▅▄▄▄▃▄▃▃▃▃▂▃▂▃▃▃▂▂▂▃▂▂▂▁▂▁▁▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/Bad_a_accuracy</td><td>0.93333</td></tr><tr><td>eval/Bassy_a_accuracy</td><td>1</td></tr><tr><td>eval/Big Room_a_accuracy</td><td>1</td></tr><tr><td>eval/Bounce_a_accuracy</td><td>0.25</td></tr><tr><td>eval/Chill_a_accuracy</td><td>0.75</td></tr><tr><td>eval/Chillstep_a_accuracy</td><td>0.33333</td></tr><tr><td>eval/Classic_a_accuracy</td><td>0.75</td></tr><tr><td>eval/Coding_a_accuracy</td><td>0</td></tr><tr><td>eval/Country_a_accuracy</td><td>0.66667</td></tr><tr><td>eval/Cro_a_accuracy</td><td>0.83333</td></tr><tr><td>eval/Deep House_a_accuracy</td><td>0</td></tr><tr><td>eval/Drum and Bass_a_accuracy</td><td>0.6</td></tr><tr><td>eval/Dubstep_a_accuracy</td><td>0</td></tr><tr><td>eval/EDM_a_accuracy</td><td>0.2</td></tr><tr><td>eval/Electro House_a_accuracy</td><td>0.72727</td></tr><tr><td>eval/Electro_a_accuracy</td><td>0.88235</td></tr><tr><td>eval/Emotional_a_accuracy</td><td>1</td></tr><tr><td>eval/Epic_a_accuracy</td><td>1</td></tr><tr><td>eval/Folk_a_accuracy</td><td>0</td></tr><tr><td>eval/Frenchcore_a_accuracy</td><td>0.57143</td></tr><tr><td>eval/Glitch Hop_a_accuracy</td><td>0</td></tr><tr><td>eval/God_a_accuracy</td><td>0</td></tr><tr><td>eval/Groove_a_accuracy</td><td>0.7</td></tr><tr><td>eval/Hands Up_a_accuracy</td><td>0.88321</td></tr><tr><td>eval/Hardcore_a_accuracy</td><td>0.75</td></tr><tr><td>eval/Hardstyle_a_accuracy</td><td>0.95455</td></tr><tr><td>eval/Harp_a_accuracy</td><td>1</td></tr><tr><td>eval/Hip Hop & Rap_a_accuracy</td><td>1</td></tr><tr><td>eval/Historic_a_accuracy</td><td>1</td></tr><tr><td>eval/Latino_a_accuracy</td><td>0.75</td></tr><tr><td>eval/Lounge_a_accuracy</td><td>0.90909</td></tr><tr><td>eval/Malle_a_accuracy</td><td>0.77778</td></tr><tr><td>eval/Minimal_a_accuracy</td><td>0.75</td></tr><tr><td>eval/Motivation_a_accuracy</td><td>0.54545</td></tr><tr><td>eval/OVERWERK_a_accuracy</td><td>1</td></tr><tr><td>eval/Orchestra Pop_a_accuracy</td><td>0.5</td></tr><tr><td>eval/Orchestral Electro_a_accuracy</td><td>0.66667</td></tr><tr><td>eval/Pop mit Beat_a_accuracy</td><td>0</td></tr><tr><td>eval/Pop_a_accuracy</td><td>0</td></tr><tr><td>eval/Psy_a_accuracy</td><td>0</td></tr><tr><td>eval/Psytrance_a_accuracy</td><td>0</td></tr><tr><td>eval/RnB_a_accuracy</td><td>0.25</td></tr><tr><td>eval/Rock_a_accuracy</td><td>0.52941</td></tr><tr><td>eval/Synthpop_a_accuracy</td><td>0</td></tr><tr><td>eval/Techno_a_accuracy</td><td>0.33333</td></tr><tr><td>eval/Tekk_a_accuracy</td><td>0.66667</td></tr><tr><td>eval/Trance_a_accuracy</td><td>0.83333</td></tr><tr><td>eval/Weihnachten_a_accuracy</td><td>0</td></tr><tr><td>eval/accuracy</td><td>0.50982</td></tr><tr><td>eval/f1</td><td>0.36763</td></tr><tr><td>eval/loss</td><td>2.52573</td></tr><tr><td>eval/max_pooling_score</td><td>0.71489</td></tr><tr><td>eval/mean_pooling_score</td><td>0.73191</td></tr><tr><td>eval/precision</td><td>0.40453</td></tr><tr><td>eval/recall</td><td>0.39588</td></tr><tr><td>eval/runtime</td><td>41.6279</td></tr><tr><td>eval/samples_per_second</td><td>56.26</td></tr><tr><td>eval/steps_per_second</td><td>0.456</td></tr><tr><td>eval/voting_score</td><td>0.67872</td></tr><tr><td>eval/weighting_score</td><td>0.75319</td></tr><tr><td>train/epoch</td><td>8.20312</td></tr><tr><td>train/global_step</td><td>1050</td></tr><tr><td>train/grad_norm</td><td>248099.76562</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.3513</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">all_without_freq_shift_and_masking_and_stretch</strong> at: <a href='https://wandb.justinkonratt.com/codesdowork/genre_classification/runs/ngu5tyyz' target=\"_blank\">https://wandb.justinkonratt.com/codesdowork/genre_classification/runs/ngu5tyyz</a><br> View project at: <a href='https://wandb.justinkonratt.com/codesdowork/genre_classification' target=\"_blank\">https://wandb.justinkonratt.com/codesdowork/genre_classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250120_131934-ngu5tyyz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
